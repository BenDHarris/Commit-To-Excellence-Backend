{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70294c2-ad1d-42f2-bae0-8c02e55ebce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installed accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5401fc6-7805-4dd5-b1d1-4a6918ba3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f7364d-4fa5-473e-8142-4baea58191f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"cte/tomasz_test/data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a34c5d9-3e4a-4527-8916-5b251a0c3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.Dataset.from_pandas(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "98a29b4e-b2e2-4ee9-a4a5-f215d0b54f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = datasets.load_dataset('csv', data_files='cte/tomasz_test/data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "79dab625-767e-4437-8dab-10542ad7dec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'Repository', 'Message', 'Diff'],\n",
       "    num_rows: 540\n",
       "})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54d0f367-62a9-4aa2-9872-0c3b5858d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(tokenize, num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f349821-ea79-4c5f-8372-227d3790c791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35121c17-b46f-4c82-b511-c9de068c687f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf77fd40-c010-4d41-873b-c2eccb503017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Repository</th>\n",
       "      <th>Message</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>swaroopch/byte-of-python</td>\n",
       "      <td>Remove Romanian translation (abandoned)\\n\\nThe...</td>\n",
       "      <td>diff --git a/translations.md b/translations.md...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>swaroopch/byte-of-python</td>\n",
       "      <td>Add link to Real Python on editor</td>\n",
       "      <td>diff --git a/first_steps.md b/first_steps.md\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>swaroopch/byte-of-python</td>\n",
       "      <td>Fix typo</td>\n",
       "      <td>diff --git a/README.md b/README.md\\nindex 85a9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>swaroopch/byte-of-python</td>\n",
       "      <td>Remove whitespace to fix header rendering\\n\\nT...</td>\n",
       "      <td>diff --git a/problem_solving.md b/problem_solv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>swaroopch/byte-of-python</td>\n",
       "      <td>Fix sentence grammar\\n\\nThanks to John Thomas.</td>\n",
       "      <td>diff --git a/basics.md b/basics.md\\nindex 3729...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>purcellconsult/Cracking-Python-Bootcamp</td>\n",
       "      <td>Create a list of written assignments\\n\\nWritte...</td>\n",
       "      <td>diff --git a/written assignments/a list of wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>536</td>\n",
       "      <td>purcellconsult/Cracking-Python-Bootcamp</td>\n",
       "      <td>Create text_based_calculator\\n\\nThe first codi...</td>\n",
       "      <td>diff --git a/coding projects/text_based_calcul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>537</td>\n",
       "      <td>purcellconsult/Cracking-Python-Bootcamp</td>\n",
       "      <td>Create 1_numbers_in_python\\n\\nPower point file...</td>\n",
       "      <td>diff --git a/power_points/1_numbers_in_python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>538</td>\n",
       "      <td>purcellconsult/Cracking-Python-Bootcamp</td>\n",
       "      <td>Add files via upload\\n\\nFirst lesson of the co...</td>\n",
       "      <td>diff --git a/1_numbers_in_python.py b/1_number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>539</td>\n",
       "      <td>purcellconsult/Cracking-Python-Bootcamp</td>\n",
       "      <td>Add files via upload\\n\\nCourse syllabus versio...</td>\n",
       "      <td>diff --git a/python3_course_syllabus.docx b/py...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                               Repository  \\\n",
       "0             0                 swaroopch/byte-of-python   \n",
       "1             1                 swaroopch/byte-of-python   \n",
       "2             2                 swaroopch/byte-of-python   \n",
       "3             3                 swaroopch/byte-of-python   \n",
       "4             4                 swaroopch/byte-of-python   \n",
       "..          ...                                      ...   \n",
       "535         535  purcellconsult/Cracking-Python-Bootcamp   \n",
       "536         536  purcellconsult/Cracking-Python-Bootcamp   \n",
       "537         537  purcellconsult/Cracking-Python-Bootcamp   \n",
       "538         538  purcellconsult/Cracking-Python-Bootcamp   \n",
       "539         539  purcellconsult/Cracking-Python-Bootcamp   \n",
       "\n",
       "                                               Message  \\\n",
       "0    Remove Romanian translation (abandoned)\\n\\nThe...   \n",
       "1                    Add link to Real Python on editor   \n",
       "2                                             Fix typo   \n",
       "3    Remove whitespace to fix header rendering\\n\\nT...   \n",
       "4       Fix sentence grammar\\n\\nThanks to John Thomas.   \n",
       "..                                                 ...   \n",
       "535  Create a list of written assignments\\n\\nWritte...   \n",
       "536  Create text_based_calculator\\n\\nThe first codi...   \n",
       "537  Create 1_numbers_in_python\\n\\nPower point file...   \n",
       "538  Add files via upload\\n\\nFirst lesson of the co...   \n",
       "539  Add files via upload\\n\\nCourse syllabus versio...   \n",
       "\n",
       "                                                  Diff  \n",
       "0    diff --git a/translations.md b/translations.md...  \n",
       "1    diff --git a/first_steps.md b/first_steps.md\\n...  \n",
       "2    diff --git a/README.md b/README.md\\nindex 85a9...  \n",
       "3    diff --git a/problem_solving.md b/problem_solv...  \n",
       "4    diff --git a/basics.md b/basics.md\\nindex 3729...  \n",
       "..                                                 ...  \n",
       "535  diff --git a/written assignments/a list of wri...  \n",
       "536  diff --git a/coding projects/text_based_calcul...  \n",
       "537  diff --git a/power_points/1_numbers_in_python ...  \n",
       "538  diff --git a/1_numbers_in_python.py b/1_number...  \n",
       "539  diff --git a/python3_course_syllabus.docx b/py...  \n",
       "\n",
       "[540 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "11022a64-6523-4119-8d80-3ee07bc3f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForCausalLM, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer, TFTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2bbf69-db9f-40ef-9927-8098d12b9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model types and sizes\n",
    "MODEL_SIZES = [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]\n",
    "MODEL_SIZE = MODEL_SIZES[0]\n",
    "MODEL_TYPES = [TFT5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForCausalLM ]\n",
    "MODEL_TYPE = MODEL_TYPES[0]\n",
    "\n",
    "# Data\n",
    "FEATURES = \"Diff\"\n",
    "TARGET = \"Message\"\n",
    "DATA = data1\n",
    "\n",
    "# Determine task for teh model (summarize, translate)\n",
    "PREFIX = \"summarize: \"\n",
    "\n",
    "# Determine maximum input for features and the target\n",
    "MAX_INPUT_LENGTH = 540\n",
    "MAX_TARGET_LENGTH = 540\n",
    "\n",
    "# Fine-Tuning Parameters\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "ADAM_BETA1 = 0.9\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Testing\n",
    "GIT_DIFF = \"random diff that is going to be used to generate comment when committed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d1d10b-903c-48e8-b3c8-59fb205c6ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 10:08:26.948685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:26.951830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:26.951862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:26.952573: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 10:08:26.954623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:26.954660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:26.954678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:29.181101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:29.181557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:29.181577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-30 10:08:29.181659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-30 10:08:29.181744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1241 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-08-30 10:08:31.625001: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration at 0x7f20abb7f850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "model = MODEL_TYPE.from_pretrained(MODEL_SIZE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80dfa58d-6599-4722-a29a-bb52eefe50ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5Tokenizer(name_or_path='t5-small', vocab_size=32100, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_SIZE)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac16c1a-dda1-430f-95ef-b564e236b7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "Repository    object\n",
       "Message       object\n",
       "Diff          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c4a697-e2dc-4029-af56-d418ba3f6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[FEATURES] = DATA[FEATURES].apply(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd349599-d679-4aa4-a718-5b30606d2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[TARGET] = DATA[TARGET].apply(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0c4d317-ad87-4ffe-9049-e99e8db39dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[TARGET] = DATA[TARGET].apply(lambda x : x.replace('\\n',' ').replace('.','').replace(',','').replace('(','').replace(')','').replace('!','').replace('+','').replace(':','').replace('/',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3810ba1-da33-44ea-b9b3-082dcd81a100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "Repository    object\n",
       "Message       object\n",
       "Diff          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20dcdcd3-863a-4f25-9f83-6a5daf9c7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(df):\n",
    "    # Setup the tokenizer for features\n",
    "    inputs = [PREFIX + difference for difference in df[FEATURES][0:10]]\n",
    "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=list(df[TARGET][0:10]), max_length=MAX_TARGET_LENGTH, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce701e5-410c-43e6-b96a-2d4c74f9dd90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a18b92b4-ace6-42e6-bdd5-bb56a0cfcbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = preprocess_function(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cad0d6e-5447-4d97-8cc9-f0bc360d80f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63460deb-162b-45ab-a964-03c57ff1fd96",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Commit-To-Excellence/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:254\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'set_format'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_format\u001b[49m(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Commit-To-Excellence/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:256\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[item]\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data3.set_format(type='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "116566cc-689a-47e0-b6de-fc9389bf3320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_ids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0       input_ids\n",
       "1  attention_mask\n",
       "2          labels"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be3e63d2-631e-433f-8ef1-c6f331acfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df =pd.DataFrame()\n",
    "new_df[\"input_ids\"] = data3[\"input_ids\"]\n",
    "new_df[\"attention_mask\"] = data3[\"attention_mask\"]\n",
    "new_df[\"labels\"] = data3[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0368923a-33ab-4d8c-93b7-b6a046a29dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 7031...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10002, 3871, 29, 7314, 13876, 37, 3871, 29, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 1467...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2334, 1309, 12, 2977, 20737, 30, 6005, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 1322...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[14269, 23042, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 1930...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10002, 872, 6633, 12, 2210, 13956, 18968, 133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 4883...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[14269, 7142, 19519, 1333, 12, 1079, 3576, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 7, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2210, 23042, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 5, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[617, 126, 747, 44, 414, 13, 689, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 5, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2270, 3, 12651, 3191, 127, 15, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 7932...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2334, 1030, 81, 128, 703, 1999, 2099, 257, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[21603, 10, 20624, 1636, 12651, 3, 9, 87, 5, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[14269, 6854, 2196, 57, 3, 476, 4815, 10376, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 7031...   \n",
       "1  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 1467...   \n",
       "2  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 1322...   \n",
       "3  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 1930...   \n",
       "4  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 4883...   \n",
       "5  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 7, 1...   \n",
       "6  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 5, 1...   \n",
       "7  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 5, 1...   \n",
       "8  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 7932...   \n",
       "9  [21603, 10, 20624, 1636, 12651, 3, 9, 87, 5, 1...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "5  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "8  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [10002, 3871, 29, 7314, 13876, 37, 3871, 29, 1...  \n",
       "1         [2334, 1309, 12, 2977, 20737, 30, 6005, 1]  \n",
       "2                                  [14269, 23042, 1]  \n",
       "3  [10002, 872, 6633, 12, 2210, 13956, 18968, 133...  \n",
       "4      [14269, 7142, 19519, 1333, 12, 1079, 3576, 1]  \n",
       "5                                   [2210, 23042, 1]  \n",
       "6               [617, 126, 747, 44, 414, 13, 689, 1]  \n",
       "7                 [2270, 3, 12651, 3191, 127, 15, 1]  \n",
       "8  [2334, 1030, 81, 128, 703, 1999, 2099, 257, 11...  \n",
       "9  [14269, 6854, 2196, 57, 3, 476, 4815, 10376, 7...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3256b28-188a-4fae-be87-498499f881ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function splitting data\n",
    "def split_data(data):\n",
    "    train_data = data.iloc[0: int(len(data)*0.7)]\n",
    "    validation_data = data.iloc[int(len(data)*0.7): int(len(data)*0.9)]\n",
    "    test_data = data.iloc[int(len(data)*0.9): len(data)-1]\n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0c577a1b-4204-496f-8ebe-4a8f123c7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "train_data, validation_data, test_data = split_data(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "df237b85-b588-481f-9770-70d84a614b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new training model based on T5 model and given new parameters\n",
    "def create_training_model(model, tokenizer, train_data, validation_data):\n",
    "\n",
    "    # create arguments for training the model\n",
    "    args = TFTrainingArguments(\n",
    "        f\"{MODEL_SIZE}-finetuned-xsum\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size= BATCH_SIZE,\n",
    "        per_device_eval_batch_size= BATCH_SIZE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        adam_beta1 = ADAM_BETA1,\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=1,\n",
    "        #predict_with_generate=True,\n",
    "        fp16=True,\n",
    "        push_to_hub=False)\n",
    "\n",
    "    # pad inputs and labels to the maximum length in the batch\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "    # model creation\n",
    "    trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=validation_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer)\n",
    "    # compute_metrics=compute_metrics not sure whether it is needed so not included\n",
    "\n",
    "    # return new training model\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ecce9dd-ad6d-432d-8e5a-23e21dabb7e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accelerate_version' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Commit to Excellence model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m CTE_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_training_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[105], line 23\u001b[0m, in \u001b[0;36mcreate_training_model\u001b[0;34m(model, tokenizer, train_data, validation_data)\u001b[0m\n\u001b[1;32m     20\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForSeq2Seq(tokenizer, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# model creation\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# compute_metrics=compute_metrics not sure whether it is needed so not included\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# return new training model\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Commit-To-Excellence/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:56\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     44\u001b[0m     model: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, nn\u001b[38;5;241m.\u001b[39mModule] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     preprocess_logits_for_metrics: Optional[Callable[[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor], torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     55\u001b[0m ):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Override self.model.generation_config if a GenerationConfig is specified in args.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Priority: args.generation_config > model.generation_config > default GenerationConfig.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Commit-To-Excellence/lib/python3.10/site-packages/transformers/trainer.py:340\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Commit-To-Excellence/lib/python3.10/site-packages/transformers/trainer.py:3878\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_accelerator_and_postprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3877\u001b[0m     grad_acc_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps}\n\u001b[0;32m-> 3878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(\u001b[43maccelerate_version\u001b[49m) \u001b[38;5;241m>\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.3\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   3879\u001b[0m         grad_acc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msync_with_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3880\u001b[0m     gradient_accumulation_plugin \u001b[38;5;241m=\u001b[39m GradientAccumulationPlugin(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgrad_acc_kwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accelerate_version' is not defined"
     ]
    }
   ],
   "source": [
    "#Commit to Excellence model\n",
    "CTE_model = create_training_model(model, tokenizer, train_data, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef12feb-bed5-4af1-9546-5f9922222773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train CTE_model\n",
    "CTE_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e132ab21-4d8c-4e71-b2bf-e893dc6abc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "def generate_comment(tokenizer, git_diff):\n",
    "    preprocessed_text= PREFIX + git_diff\n",
    "\n",
    "    encoding_test = tokenizer.encode(preprocessed_text,return_tensors=\"tf\")\n",
    "\n",
    "    summary_ids = CTE_model.generate(encoding_test, min_length=60, max_length=80)\n",
    "\n",
    "    commit_message = tokenizer.decode(summary_ids[0])\n",
    "\n",
    "    return commit_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa1043a-7d25-4ef7-9142-0ebe7c8c7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_comment(tokenizer, GIT_DIFF)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c29e3c-ed85-40a5-91af-8c6a9a7e2dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
